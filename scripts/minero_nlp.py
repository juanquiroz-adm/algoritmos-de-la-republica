import pdfplumber
import re
from collections import Counter

# Nombre del archivo que ya tienes descargado
archivo = "ps19_elsiglo_febrero_1893.pdf"

# Lista de palabras in√∫tiles que no queremos contar (Stopwords b√°sicas)
stopwords = ['de', 'la', 'el', 'en', 'y', 'a', 'los', 'que', 'por', 'las', 'con', 'un', 'para', 'una', 'su', 'se', 'del', 'al', 'es', 'como', 'o']

print(f"--- INICIANDO EXTRACCI√ìN Y MINER√çA DE TEXTO ---")
print(f"Procesando: {archivo}...\n")

texto_completo = ""

try:
    # 1. EXTRACCI√ìN
    with pdfplumber.open(archivo) as pdf:
        # Leemos todas las p√°ginas del PDF
        for i, pagina in enumerate(pdf.pages):
            texto_extraido = pagina.extract_text()
            if texto_extraido:
                texto_completo += texto_extraido + " "
                
    print(f"‚úÖ Extracci√≥n completada. Caracteres totales le√≠dos: {len(texto_completo)}")

    # 2. LIMPIEZA DE DATOS (Transformaci√≥n)
    # Convertimos todo a min√∫sculas
    texto_limpio = texto_completo.lower()
    # Quitamos signos de puntuaci√≥n y n√∫meros usando Regex (dejamos solo letras)
    texto_limpio = re.sub(r'[^a-z√°√©√≠√≥√∫√±]+', ' ', texto_limpio)
    
    # Separamos en palabras
    palabras = texto_limpio.split()
    
    # Filtramos las stopwords y palabras muy cortas
    palabras_utiles = [palabra for palabra in palabras if palabra not in stopwords and len(palabra) > 3]

    print(f"‚úÖ Limpieza completada. Palabras √∫tiles a analizar: {len(palabras_utiles)}\n")

    # 3. AN√ÅLISIS (Frecuencia)
    # Contamos las palabras m√°s comunes
    contador = Counter(palabras_utiles)
    top_10 = contador.most_common(10)

    print("üìä TOP 10 PALABRAS M√ÅS FRECUENTES EN EL DOCUMENTO:")
    for palabra, frecuencia in top_10:
        print(f" - {palabra.upper()}: {frecuencia} veces")

    print("\n‚úÖ CICLO COMPLETO DE MINER√çA SUPERADO.")

except Exception as e:
    print(f"‚ùå Error en el procesamiento: {e}")